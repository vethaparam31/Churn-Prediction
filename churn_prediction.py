# -*- coding: utf-8 -*-
"""Churn Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1thD_ibYkkW-ELCcssIMLOT6pjVinbOXB

Setup
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import xgboost as xgb
import warnings
warnings.filterwarnings('ignore')

print(" All libraries imported successfully!")

from google.colab import drive
drive.mount('/content/drive')

"""Load and Explore the Data"""

def load_spotify_data():
    import pandas as pd

    print("ðŸ“Š Loading Spotify dataset...")

    # If your file is an Excel file
    df = pd.read_excel("/content/drive/MyDrive/Colab Notebooks/Spotify_data.xlsx")

    return df


df = load_spotify_data()

print("\nâœ… Dataset Loaded Successfully!")
print("Shape:", df.shape)
print("\nFirst 5 rows:")
print(df.head())
print("\nDataset Info:")
print(df.info())
print("\nMissing Values:")
print(df.isnull().sum())

"""Data Cleaning & Preprocessing"""

df['churn'] = (df['premium_sub_willingness'] == 'No').astype(int)

print("Churn Distribution:")
print(df['churn'].value_counts())
print(f"Churn Rate: {df['churn'].mean():.2%}")
print("\nðŸ”§ Handling missing values...")
for col in df.columns:
    if df[col].isnull().sum() > 0:
        if df[col].dtype == 'object':
            df[col].fillna('Unknown', inplace=True)
        else:
            df[col].fillna(df[col].median(), inplace=True)
categorical_cols = ['Gender', 'spotify_usage_period', 'spotify_listening_device',
                   'spotify_subscription_plan', 'preffered_premium_plan',
                   'preferred_listening_content', 'fav_music_genre',
                   'music_time_slot', 'music_Influencial_mood',
                   'music_lis_frequency', 'music_expl_method',
                   'pod_lis_frequency', 'fav_pod_genre',
                   'preffered_pod_format', 'pod_host_preference',
                   'preffered_pod_duration', 'pod_variety_satisfaction']
label_encoders = {}
for col in categorical_cols:
    if col in df.columns:
        le = LabelEncoder()
        df[col + '_encoded'] = le.fit_transform(df[col].astype(str))
        label_encoders[col] = le

print(" Data cleaning completed!")

"""Feature Engineering"""

print("Creating features for churn prediction...")
df['multiple_devices'] = df['spotify_listening_device'].str.contains(',').astype(int)
frequency_mapping = {'Never': 0, 'Rarely': 1, 'Once a week': 2,
                    'Several times a week': 3, 'Daily': 4}
df['usage_frequency_score'] = df['music_lis_frequency'].map(frequency_mapping)
df['podcast_listener'] = (df['preferred_listening_content'] == 'Podcast').astype(int)
df['long_term_user'] = df['spotify_usage_period'].isin(['More than 2 years', '1 year to 2 years']).astype(int)
if 'music_recc_rating' in df.columns:
    df['satisfaction_score'] = pd.to_numeric(df['music_recc_rating'], errors='coerce')

print("Feature engineering completed!")
print(f"Total features created: {len(df.columns)}")

"""Prepare Data for Modeling"""

feature_columns = [col for col in df.columns if col.endswith('_encoded')] + \
                 ['multiple_devices', 'usage_frequency_score', 'podcast_listener',
                  'long_term_user', 'satisfaction_score']
feature_columns = [col for col in feature_columns if col in df.columns]

print("Selected features:", feature_columns)

X = df[feature_columns]
y = df['churn']
X = X.fillna(X.median())
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,
                                                    random_state=42, stratify=y)

print(f"Training set: {X_train.shape}")
print(f"Test set: {X_test.shape}")
print(f"Churn rate in training: {y_train.mean():.2%}")
print(f"Churn rate in test: {y_test.mean():.2%}")

"""Build and Train Models"""

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')
X_train = imputer.fit_transform(X_train)
X_test = imputer.transform(X_test)

models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'XGBoost': xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
}

results = {}

for name, model in models.items():
    print(f"\n Training {name}...")
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    results[name] = {
        'model': model,
        'predictions': y_pred,
        'probabilities': y_pred_proba,
        'auc_score': roc_auc_score(y_test, y_pred_proba)
    }

    print(f"{name} trained - AUC: {results[name]['auc_score']:.4f}")

"""Model Evaluation"""

from sklearn.metrics import precision_recall_fscore_support

print(" MODEL EVALUATION RESULTS")
print("="*50)

for name, result in results.items():
    y_pred = result['predictions']

    # Calculate metrics
    precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')
    accuracy = (y_pred == y_test).mean()

    print(f"\n{name}:")
    print(f"  Accuracy:  {accuracy:.4f}")
    print(f"  Precision: {precision:.4f}")
    print(f"  Recall:    {recall:.4f}")
    print(f"  F1-Score:  {fscore:.4f}")
    print(f"  AUC:       {result['auc_score']:.4f}")

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    print(f"  Confusion Matrix:\n{cm}")

# Find best model
best_model_name = max(results.keys(), key=lambda x: results[x]['auc_score'])
best_model = results[best_model_name]['model']
print(f"\n BEST MODEL: {best_model_name}")

"""Feature Importance Analysis"""

if hasattr(best_model, 'feature_importances_'):
    n_features_model = len(best_model.feature_importances_)
    n_features_list = len(feature_columns)

    # If mismatch, adjust automatically
    if n_features_model != n_features_list:
        print(f"Length mismatch: Model has {n_features_model} features, but list has {n_features_list}. Adjusting...")
        feature_columns = feature_columns[:n_features_model]

    feature_importance = pd.DataFrame({
        'feature': feature_columns,
        'importance': best_model.feature_importances_[:len(feature_columns)]
    }).sort_values('importance', ascending=False)

    print("\n TOP 10 FEATURE IMPORTANCES:")
    print(feature_importance.head(10))

    plt.figure(figsize=(10, 6))
    sns.barplot(data=feature_importance.head(10), x='importance', y='feature')
    plt.title('Top 10 Feature Importances for Churn Prediction')
    plt.tight_layout()
    plt.show()

# Correlation with churn (only for numeric features)
numeric_features = [col for col in feature_columns if df[col].dtype in ['int64', 'float64']]

churn_correlation = pd.DataFrame({
    'feature': numeric_features,
    'correlation': [np.corrcoef(df[col], df['churn'])[0, 1] if df[col].notnull().sum() > 1 else 0 for col in numeric_features]
}).sort_values('correlation', key=abs, ascending=False)

print("\n TOP CORRELATIONS WITH CHURN:")
print(churn_correlation.head(10))

"""Create Business Insights Dashboard"""

# Create comprehensive visualizations
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# 1. Churn distribution by subscription plan
churn_by_plan = df.groupby('spotify_subscription_plan')['churn'].mean().sort_values(ascending=False)
sns.barplot(x=churn_by_plan.values, y=churn_by_plan.index, ax=axes[0,0])
axes[0,0].set_title('Churn Rate by Subscription Plan')
axes[0,0].set_xlabel('Churn Rate')

# 2. Churn by usage period
churn_by_usage = df.groupby('spotify_usage_period')['churn'].mean()
sns.barplot(x=churn_by_usage.values, y=churn_by_usage.index, ax=axes[0,1])
axes[0,1].set_title('Churn Rate by Usage Period')
axes[0,1].set_xlabel('Churn Rate')

# 3. Churn by gender
churn_by_gender = df.groupby('Gender')['churn'].mean()
sns.barplot(x=churn_by_gender.values, y=churn_by_gender.index, ax=axes[1,0])
axes[1,0].set_title('Churn Rate by Gender')
axes[1,0].set_xlabel('Churn Rate')

# 4. Churn by music recommendation rating
if 'music_recc_rating' in df.columns:
    df['music_recc_rating_num'] = pd.to_numeric(df['music_recc_rating'], errors='coerce')
    rating_churn = df.groupby('music_recc_rating_num')['churn'].mean()
    axes[1,1].plot(rating_churn.index, rating_churn.values, marker='o')
    axes[1,1].set_title('Churn Rate by Recommendation Rating')
    axes[1,1].set_xlabel('Rating')
    axes[1,1].set_ylabel('Churn Rate')

plt.tight_layout()
plt.show()

# Key insights summary
print(" KEY BUSINESS INSIGHTS:")
print("="*40)
print(f"Overall Churn Rate: {df['churn'].mean():.2%}")
print(f"Highest churn subscription: {churn_by_plan.index[0]} ({churn_by_plan.iloc[0]:.2%})")
print(f"Lowest churn subscription: {churn_by_plan.index[-1]} ({churn_by_plan.iloc[-1]:.2%})")
print(f"Best performing model: {best_model_name} (AUC: {results[best_model_name]['auc_score']:.4f})")

"""Generate Business Report"""

# Create a summary report
def generate_business_report(results, df):
    report = f"""
     SPOTIFY CHURN PREDICTION ANALYSIS REPORT
    {'='*50}

    EXECUTIVE SUMMARY:
    â€¢ Dataset: {df.shape[0]} customers, {df.shape[1]} features
    â€¢ Overall Churn Rate: {df['churn'].mean():.2%}
    â€¢ Best Model: {best_model_name} with AUC: {results[best_model_name]['auc_score']:.4f}

    KEY FINDINGS:
    1. High churn observed among {churn_by_plan.index[0]} users
    2. Long-term users show {'higher' if churn_by_usage.iloc[-1] > churn_by_usage.iloc[0] else 'lower'} churn rates
    3. Top churn drivers: {', '.join(feature_importance['feature'].head(3).tolist())}

    RECOMMENDATIONS:
    â€¢ Focus retention efforts on {churn_by_plan.index[0]} plan users
    â€¢ Improve experience for new users (first 6 months)
    â€¢ Monitor {feature_importance['feature'].iloc[0]} as key churn indicator

    MODEL PERFORMANCE:
    """

    for name, result in results.items():
        y_pred = result['predictions']
        accuracy = (y_pred == y_test).mean()
        report += f"    â€¢ {name}: Accuracy = {accuracy:.4f}, AUC = {result['auc_score']:.4f}\n"

    return report

print(generate_business_report(results, df))

"""Results and model"""

joblib.dump(best_model, 'spotify_churn_model.pkl')
print("Best model saved as 'spotify_churn_model.pkl'")

if not isinstance(X_test, pd.DataFrame):
    X_test = pd.DataFrame(X_test, columns=feature_columns)
    X_test.index = y_test.index  # align indices with y_test

predictions_df = pd.DataFrame({
    'actual_churn': y_test,
    'predicted_churn': results[best_model_name]['predictions'],
    'churn_probability': results[best_model_name]['probabilities']
})

predictions_df = pd.concat(
    [predictions_df, df.loc[y_test.index, ['spotify_subscription_plan', 'Gender', 'spotify_usage_period']]],
    axis=1
)

predictions_df.to_csv('churn_predictions.csv', index=False)
print(" Predictions saved as 'churn_predictions.csv'")
print("\n PROJECT COMPLETED SUCCESSFULLY!")